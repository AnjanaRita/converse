{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1ac07e-1d5e-4a64-b235-3d57c1adb274",
   "metadata": {},
   "source": [
    "# PyConverse Basic usage:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5647d1ed-1675-497e-b793-344e1b7d54d3",
   "metadata": {},
   "source": [
    "Import necessary functions and class from pyconverse\n",
    "\n",
    "_**Note: first time you install pyconverse and make these imports it downloads few transformers models, sentence-transformers in the backend hence the first import might take few minutes.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a0438-3d5a-4b2d-b7f6-55a1ce418533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from pyconverse import Callyzer, SpeakerStats\n",
    "from pyconverse import SemanticTextSegmention, ZeroShotTopicFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8fd363-3e3c-44d0-985d-9d0343ac7a7f",
   "metadata": {},
   "source": [
    "## Load sample dataset\n",
    "\n",
    "_**Note: to load your own transcript dataset, let's say from aws-transcribe, google-cloud, azure etc or any other services, you would need to convert your transcripts into a pandas dataframe and while you initialize the `Callyzer` class, you need to point towards the speaker, utterance, start-time & end-time for each utterance.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c183ff-229e-44b1-b145-57463c516fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df = pd.read_csv(\"sample_transcript_data.csv\"); transcript_df.head() #read sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c8bdc-16e2-4ad5-a9d7-6445b5462fb0",
   "metadata": {},
   "source": [
    "## Analyse the Call transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096d1d03-79ff-4ed3-b826-e79a32f86eda",
   "metadata": {},
   "source": [
    "Initialise the core call analysis class `Callyzer` with your dataset represented as a pandas dataframe and point towards utterance, speaker, start-time & end-time columns in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ce707-8d81-4f21-b85b-e81ffb2ec3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_analysis = Callyzer(data=transcript_df, utterance=\"utterance\", speaker=\"speaker\", starttime=\"start_time\", endtime=\"end_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bb77ce-70d2-4cb5-879c-0ad953facf3e",
   "metadata": {},
   "source": [
    "compute and access various attributes of the call as follows: \n",
    "\n",
    "## Find Interruptions and periods of silence in a call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcca4d5-9bf6-4a24-b220-27acface05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interruptions = transcript_analysis.get_interruption() #interruption periods in a call\n",
    "silence = transcript_analysis.get_silence() #periods of silence in a call\n",
    "\n",
    "print(\"1. INTERRUPTIONS:\\n\")\n",
    "pprint(interruptions)\n",
    "\n",
    "print(\"\\n2. PERIODS OF SILENCE:\\n\")\n",
    "pprint(silence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12d924f-f9b3-4cba-b300-46a7c4fa945f",
   "metadata": {},
   "source": [
    "## Find the Backchannel utterances in a call transcripts.\n",
    "\n",
    "\n",
    "Backchannels can be verbal, non-verbal (visual) or both. Vocalisations like 'hmm' or 'uh-huh', gestures such as head nods or head shakes, and a combination of verbal and non-verbal responses are common examples of backchannels. `pyconverse` identifies verbal backchannels using two different methods: \n",
    "\n",
    "1. default : via a set of commonly used backchannel keywords dictionary - fast, slightly low accuracy.\n",
    "2. nlp: via sentence similarity with sentence-transformers - slow, high accuracy. \n",
    "\n",
    "_**Note: the backchannel identification with sentence similarity implementation is  highly inspired by facebook's [Unsupervised Topic Segmentation of Meetings with BERT Embeddings](https://arxiv.org/abs/2106.12978) paper.**_\n",
    "\n",
    "The way this works is by taking common backchannel words like \"okay\", \"thats it\", \"ummhhh\" etc as backchannel samples and then do maxpool and  we apply sentence similarity with all utterances in the transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc396b98-916f-4a77-b4de-3add2d0a4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "backchannels_via_keywords = transcript_analysis.tag_backchannel().query(\"is_backchannel == True\") #identify backchannel utterances via keywords\n",
    "backchannels_via_transformers = transcript_analysis.tag_backchannel(type='nlp').query(\"is_backchannel == True\") #identify backchannel utterances with sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc5c81e-5075-40bf-a98a-12544020b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "backchannels_via_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662b3b9-eeb4-4a82-b4c0-6c0c246e6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "backchannels_via_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03daf33-92dc-4654-8f3b-0175e587510f",
   "metadata": {},
   "source": [
    "backchannel detection with keywords returned with **39 utterances** vs backchannel detection with sentence-transformers returned with **68 utterances**! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b045ff1-a678-43af-b246-82ddc57dcb4e",
   "metadata": {},
   "source": [
    "## Find the utterances which are interrogative questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82beca7a-7ad1-4038-8d55-3b81954ea9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions = transcript_analysis.tag_questions().query(\"is_question == True\") #identiy utterances which are questions\n",
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd4cc4-0fab-426f-921a-13d3737dcaac",
   "metadata": {},
   "source": [
    "## Identify the emotions of the utterances\n",
    "\n",
    "note: this might take some time as it uses miniLM language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f1d63-94ca-4407-8b33-0f63f9a182b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_analysis_ = Callyzer(transcript_df.tail(), utterance=\"utterance\", speaker=\"speaker\", starttime=\"start_time\", endtime=\"end_time\")\n",
    "\n",
    "emotions = transcript_analysis_.tag_emotion(); emotions[[\"speaker\", \"utterance\", \"emotion\"]]\n",
    "#if no emotionis identified, it returns 'not found'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec8ed2-408b-40c2-8726-cecdc20156e4",
   "metadata": {},
   "source": [
    "## Identify if a given utterance is empathetic or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f6df43-11c2-49d3-8728-f58aca2ffd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "empathy = transcript_analysis_.tag_empathy(); empathy[[\"speaker\", \"utterance\", \"is_empathy\"]]\n",
    "#if no empathy is identified, it classifies the sentence as 'non_empathetic', if identified it returns 'empathetic'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b082c3-42a1-4569-8128-5720c5eaa111",
   "metadata": {},
   "source": [
    "## Collapse utterances into Turn level text chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e308127-14f7-44be-b22c-53eaa85726b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data at speaker level to turn level\n",
    "df = transcript_analysis.convert_at_turn()\n",
    "\n",
    "print(f\"1. Original Utterance count: {transcript_df.shape[0]}\\n2. After collapsing the utterance to turn level: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863fa99-f01d-4c37-9790-17f59221e73b",
   "metadata": {},
   "source": [
    "## Identiy the overall Psycological correlatedness nature of the speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f319f7f8-8728-4062-8082-06f0a9efabb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SpeakerStats(df, speaker='speaker')\n",
    "pprint(ss.get_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89641437-bfc7-4e62-8b42-c9cfe86b10c5",
   "metadata": {},
   "source": [
    "## Call segmentation\n",
    "\n",
    "lets segment our calls into bigger chunks of texts via semantic sentence similairty & text tilling algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4e3f6-63ea-40f5-8956-e613b3cee155",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts = SemanticTextSegmention(df)\n",
    "segments = sts.get_segments()\n",
    "\n",
    "for segment in segments[0:4]:\n",
    "    pprint(segment)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4947df56-4480-4402-8d4b-6eb35f771b48",
   "metadata": {},
   "source": [
    "## ZeroShot topic identification\n",
    "\n",
    "Identify topics being discussed in a call via zero shot topic infernce at utterance/segment level (works best on segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c52d1e-0a19-4a6e-8c9f-85c0a9d3df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "zst = ZeroShotTopicFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98644e5f-8da0-4c8c-bcb5-e26e4d9547e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in segments[0:2]:\n",
    "    print(f\"Text: {text}\\n\")\n",
    "    print(f\"Topics: {zst.find_topic(text)}\\n\")\n",
    "    print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
